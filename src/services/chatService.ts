import { retrievalService } from './retrievalService';
import { storageService } from './storageService';
import { ChatMessage, Conversation } from '../types/chat';
import OpenAIService from './openaiService';
import { monitoringService } from './monitoringService';

const SYSTEM_PROMPTS = {
    LEGAL: `Ste pr√°vny AI asistent. Va≈°e odpovede by mali by≈•:
1. Presn√© a zalo≈æen√© na pr√°vnych princ√≠poch
2. Jasn√© a dobre ≈°trukt√∫rovan√©
3. Profesion√°lne v t√≥ne
4. Zameran√© na konkr√©tnu ot√°zku
5. Obsahova≈• relevantn√© pr√°vne cit√°cie, keƒè je to vhodn√©`
};

class ChatService {
    private openAIService: OpenAIService;

    constructor() {
        this.openAIService = OpenAIService.getInstance();
    }

    /**
     * Handles the main chat workflow: processes user questions, classifies them, and generates responses.
     * @param userId - The ID of the user initiating the chat.
     * @param question - The user's question.
     * @param conversationId - Optional ID of an existing conversation.
     * @returns The generated response.
     */
    async handleChat(userId: string, question: string, conversationId?: string): Promise<string> {
        console.log('\nüöÄ ===== Zaƒç√≠nam spracovanie ot√°zky =====');
        console.log('üìù Ot√°zka:', question);
        console.log('üîë Socket ID:', userId);
        console.log('ID konverz√°cie:', conversationId || 'Nov√° konverz√°cia');

        // Load or create a conversation
        let conversation: Conversation = conversationId
            ? await storageService.getConversation(conversationId)
            : await storageService.createConversation(userId);

        let finalAnswer: string;
        const responseId = monitoringService.startResponseTracking(conversation.id);

        // Loop to handle corrections
        while (true) {
            // First, get the classification and reasoning
            const { classification, reasoning } = await this.classifyQuestionWithOpenAI(question, conversation.history);
            
            console.log('\nü§ñ Zaƒç√≠nam OpenAI klasifik√°ciu...');
            console.log('üìä ===== V√ùSLEDKY KLASIFIK√ÅCIE =====');
            console.log('üìå Typ:', classification);
            console.log('üîç Anal√Ωza:', reasoning);
            console.log('üõ£Ô∏è Cesta spracovania:', this.getProcessingPath(classification));
            console.log('=====================================');

            // Process the question based on its type
            switch (classification) {
                case 'specific_document':
                    console.log('\nüîç ===== POU≈Ω√çVAM RAG: VYHƒΩAD√ÅVANIE KONKR√âTNEHO DOKUMENTU =====');
                    console.log('üìö Vyhƒæad√°vam relevantn√© sekcie v pr√°vnych dokumentoch...');
                    finalAnswer = await retrievalService.getSpecificDocument(question, conversation.id);
                    console.log('‚úÖ RAG spracovanie dokonƒçen√©');
                    console.log('==============================================');
                    break;
                case 'legal_analysis':
                    console.log('\nüîç ===== POU≈Ω√çVAM RAG: PR√ÅVNA ANAL√ùZA =====');
                    console.log('üìö Z√≠skavam relevantn√Ω pr√°vny kontext...');
                    finalAnswer = await this.handleLegalAnalysis(question, conversation.history, conversation.id);
                    console.log('‚úÖ RAG spracovanie dokonƒçen√©');
                    console.log('==============================================');
                    break;
                case 'general':
                    console.log('\n‚ö†Ô∏è BEZ RAG: Pou≈æ√≠vam priamu OpenAI odpoveƒè');
                    console.log('‚ÑπÔ∏è Ot√°zka nevy≈æaduje kontext pr√°vnych dokumentov');
                    finalAnswer = await this.generateDirectAnswer(question, conversation.history);
                    break;
                case 'continuation':
                    console.log('\nüîÑ Spracovanie pokraƒçovania');
                    console.log('üìù Pou≈æ√≠vam hist√≥riu konverz√°cie pre kontext');
                    finalAnswer = await this.handleContinuation(question, conversation.history);
                    break;
                case 'special_command':
                    console.log('\n‚öôÔ∏è Spracovanie ≈°peci√°lneho pr√≠kazu');
                    finalAnswer = await this.handleSpecialCommand(question, conversation.history);
                    break;
                default:
                    console.log('\n‚ö†Ô∏è Nezn√°my typ ot√°zky, pou≈æ√≠vam v≈°eobecn√Ω handler');
                    console.log('‚ÑπÔ∏è Pou≈æ√≠vam priamu OpenAI odpoveƒè bez RAG');
                    finalAnswer = await this.generateDirectAnswer(question, conversation.history);
            }

            console.log('=== Koniec spracovania ===\n');

            // Save the question and answer to the conversation history
            await storageService.saveMessage(conversation.id, {
                role: 'user',
                content: question
            });
            await storageService.saveMessage(conversation.id, {
                role: 'assistant',
                content: finalAnswer
            });

            // Check if the user is correcting a previous question
            if (this.isCorrection(question)) {
                console.log('Detekovan√° po≈æiadavka na opravu, spracov√°vam znova...');
                question = this.extractCorrectedQuestion(question);
                continue; // Reclassify the corrected question
            }
            break; // Exit if no correction is needed
        }

        // Get total metrics for this response
        const metrics = monitoringService.getMetrics(conversation.id);
        const totalCosts = monitoringService.getTotalCosts(conversation.id);

        console.log('\nüìä ===== METRIKY ODPOVEDE =====');
        console.log(`‚è±Ô∏è Celkov√Ω ƒças: ${totalCosts.totalDuration}ms`);
        console.log(`üí∞ Celkov√© n√°klady: $${(totalCosts.totalPromptCost + totalCosts.totalResponseCost).toFixed(4)}`);
        console.log(`üìù Poƒçet promptov: ${metrics.prompts.length}`);
        console.log(`üí¨ Poƒçet odpoved√≠: ${metrics.responses.length}`);
        console.log('================================\n');

        monitoringService.endResponseTracking(
            conversation.id,
            responseId,
            metrics.prompts.reduce((sum, p) => sum + p.tokens.prompt + p.tokens.completion, 0),
            totalCosts.totalPromptCost + totalCosts.totalResponseCost
        );

        console.log('üì§ Odosielam odpoveƒè klientovi...');
        console.log('‚úÖ ===== SPRACOVANIE OT√ÅZKY DOKONƒåEN√â =====');
        return finalAnswer;
    }

    /**
     * Classifies the user's question into a specific type using OpenAI.
     * @param question - The user's input.
     * @param history - Previous messages in the conversation.
     * @returns The classified question type and reasoning.
     */
    public async classifyQuestionWithOpenAI(question: string, history: ChatMessage[]): Promise<{ classification: string; reasoning: string }> {
        try {
            console.log('\n=== OpenAI klasifik√°cia ot√°zky ===');
            console.log('Ot√°zka:', question);
            console.log('Dƒ∫≈æka hist√≥rie:', history.length);

            const classificationPrompt = `Analyzujte t√∫to pr√°vnu ot√°zku a klasifikujte ju do jednej z t√Ωchto kateg√≥ri√≠:
1. specific_document - Ak sa p√Ωtate na konkr√©tny z√°kon, rozhodnutie alebo dokument (napr. "ƒåo hovor√≠ ¬ß123 Z√°kona ƒç. 40/1964?", "ƒåo hovor√≠ Obchodn√Ω z√°konn√≠k o...", "Ako je definovan√© v Z√°konn√≠ku pr√°ce...")
2. legal_analysis - Ak vy≈æaduje pr√°vnu anal√Ωzu alebo √∫vahu (napr. "Ak√© s√∫ po≈æiadavky na podanie patentu?", "Ak√© s√∫ podmienky pre zalo≈æenie s.r.o.?")
3. general - Ak ide o v≈°eobecn√∫ ot√°zku o pr√°vnych konceptoch (napr. "ƒåo je to autorsk√© pr√°vo?", "ƒåo je to obchodn√° spoloƒçnos≈•?")
4. continuation - Ak pokraƒçujete v predch√°dzaj√∫cej t√©me (napr. "Povedz mi viac o tom", "M√¥≈æe≈° to vysvetli≈• podrobnej≈°ie")
5. special_command - Ak ide o ≈°peci√°lny pr√≠kaz (napr. "zhr≈à to", "exportuj konverz√°ciu")

Ot√°zka: ${question}

Predch√°dzaj√∫ci kontext konverz√°cie:
${history.map(msg => `${msg.role}: ${msg.content}`).join('\n')}

Odpovedzte POUZE n√°zvom kateg√≥rie, niƒç in√©.`;

            console.log('\nKlasifikaƒçn√Ω prompt:');
            console.log(classificationPrompt);

            const classification = await this.openAIService.generateResponse(classificationPrompt, SYSTEM_PROMPTS.LEGAL, history[0]?.content || 'new_conversation');

            // Get detailed reasoning for the classification
            const reasoningPrompt = `Analyzujte t√∫to pr√°vnu ot√°zku a poskytnite detailn√© vysvetlenie:
Ot√°zka: ${question}

Pros√≠m poskytnite:
1. Preƒço je to pr√°vna ot√°zka
2. ƒåi vy≈æaduje RAG (Retrieval Augmented Generation)
3. Ak√© typy pr√°vnych dokumentov alebo kontextu by boli relevantn√©
4. Preƒço bola klasifikovan√° ako "${classification}"
5. Ak√© konkr√©tne aspekty ot√°zky viedli k tejto klasifik√°cii

Form√°t odpovede:
PR√ÅVNA OT√ÅZKA: [√Åno/Nie] - [Vysvetlenie]
RAG POTREBN√ù: [√Åno/Nie] - [Vysvetlenie]
RELEVANTN√ù KONTEXT: [Typy dokumentov/kontextu potrebn√©]
KLASIFIK√ÅCIA: [Kateg√≥ria] - [Vysvetlenie]
KƒΩ√öƒåOV√â FAKTORY: [Zoznam faktorov, ktor√© viedli k klasifik√°cii]`;

            const reasoning = await this.openAIService.generateResponse(reasoningPrompt, SYSTEM_PROMPTS.LEGAL, history[0]?.content || 'new_conversation');

            return {
                classification: classification.trim().toLowerCase(),
                reasoning
            };
        } catch (error) {
            console.error('Chyba pri klasifik√°cii ot√°zky:', error);
            throw error;
        }
    }

    public getProcessingPath(questionType: string): string {
        switch (questionType) {
            case 'specific_document':
                return 'retrievalService.getSpecificDocument() -> Direct document lookup with RAG';
            case 'legal_analysis':
                return 'handleLegalAnalysis() -> RAG-based analysis with document context';
            case 'general':
                return 'generateDirectAnswer() -> Direct OpenAI response without RAG';
            case 'continuation':
                return 'handleContinuation() -> Context-aware follow-up response';
            case 'special_command':
                return 'handleSpecialCommand() -> Special operation handler';
            default:
                return 'Unknown processing path';
        }
    }

    /**
     * Checks if the question requests a specific document (e.g., law or ruling).
     */
    private isSpecificDocumentRequest(question: string): boolean {
        // Check for specific law references
        const hasLawReference = /law no\.|ruling no\.|¬ß|z√°konn√≠k|z√°kon/i.test(question);
        
        // Check for court ruling references
        const hasRulingReference = /rozhodnutie|rozsudok|s√∫d/i.test(question);
        
        // Check for legal document types
        const hasLegalDocType = /trest|penalties|sanctions|trestn√Ω|trestn√©/i.test(question);
        
        const isSpecific = hasLawReference || hasRulingReference || hasLegalDocType;
        
        console.log('Legal Document Check:');
        console.log('- Has Law Reference:', hasLawReference);
        console.log('- Has Ruling Reference:', hasRulingReference);
        console.log('- Has Legal Doc Type:', hasLegalDocType);
        console.log('Final Result:', isSpecific ? 'Yes - Using RAG' : 'No');
        
        return isSpecific;
    }

    /**
     * Handles legal analysis questions with subtypes (explanation, comparison, hypothesis).
     */
    public async handleLegalAnalysis(question: string, history: ChatMessage[], conversationId: string): Promise<string> {
        try {
            console.log('\n=== Zaƒç√≠nam pr√°vnu anal√Ωzu ===');
            console.log('Ot√°zka:', question);
            console.log('Dƒ∫≈æka hist√≥rie:', history.length);

            const searchResults = await retrievalService.searchRelevantDocuments(question, conversationId);
            console.log(`Na≈°iel som ${searchResults.length} relevantn√Ωch dokumentov pre anal√Ωzu`);

            const context = retrievalService.formatSearchResults(searchResults);
            console.log('Dƒ∫≈æka kontextu:', context.length);

            const prompt = `Na z√°klade nasleduj√∫ceho pr√°vneho kontextu a ot√°zky poskytnite detailn√∫ pr√°vnu anal√Ωzu:
Kontext: ${context}

Ot√°zka: ${question}

Pros√≠m poskytnite:
1. Kƒæ√∫ƒçov√© pr√°vne z√°sady
2. Relevantn√© z√°kony a predpisy
3. Anal√Ωzu situ√°cie
4. Potenci√°lne d√¥sledky
5. S√∫visiace precedenty alebo pr√≠pady`;

            console.log('\nAnalytick√Ω prompt:');
            console.log(prompt);

            const response = await this.openAIService.generateResponse(prompt, SYSTEM_PROMPTS.LEGAL, conversationId);
            
            console.log('\n=== Vygenerovan√° pr√°vna anal√Ωza ===');
            console.log(response);
            console.log('=== Koniec pr√°vnej anal√Ωzy ===\n');

            return response;
        } catch (error) {
            console.error('Chyba v pr√°vnej anal√Ωze:', error);
            throw error;
        }
    }

    /**
     * Generates a direct answer for general questions without RAG.
     */
    public async generateDirectAnswer(question: string, history: ChatMessage[]): Promise<string> {
        const prompt = `Hist√≥ria: ${JSON.stringify(history)}\nOt√°zka: ${question}`;
        return await this.openAIService.generateResponse(prompt, SYSTEM_PROMPTS.LEGAL, history[0]?.content || 'new_conversation');
    }

    /**
     * Handles follow-up questions by considering the conversation context.
     */
    public async handleContinuation(question: string, history: ChatMessage[]): Promise<string> {
        try {
            console.log('\n=== Zaƒç√≠nam spracovanie pokraƒçovania ===');
            console.log('Ot√°zka:', question);
            console.log('Predch√°dzaj√∫ci kontext:', history[history.length - 1]?.content);

            const lastMessage = history[history.length - 1];
            const prompt = `Toto je pokraƒçovanie predch√°dzaj√∫cej ot√°zky. Predch√°dzaj√∫ci kontext:
${lastMessage.content}

Aktu√°lna ot√°zka: ${question}

Pros√≠m poskytnite odpoveƒè, ktor√° nadv√§zuje na predch√°dzaj√∫ci kontext.`;

            console.log('\nPrompt pre pokraƒçovanie:');
            console.log(prompt);

            const response = await this.openAIService.generateResponse(prompt, SYSTEM_PROMPTS.LEGAL, history[0]?.content || 'new_conversation');
            
            console.log('\n=== Vygenerovan√° odpoveƒè na pokraƒçovanie ===');
            console.log(response);
            console.log('=== Koniec pokraƒçovania ===\n');

            return response;
        } catch (error) {
            console.error('Chyba pri spracovan√≠ pokraƒçovania:', error);
            throw error;
        }
    }

    /**
     * Processes special commands like summarization or export.
     */
    public async handleSpecialCommand(question: string, history: ChatMessage[]): Promise<string> {
        try {
            console.log('\n=== Zaƒç√≠nam spracovanie ≈°peci√°lneho pr√≠kazu ===');
            console.log('Pr√≠kaz:', question);

            const prompt = `Spracujte tento ≈°peci√°lny pr√≠kaz:
${question}

Pros√≠m poskytnite vhodn√∫ odpoveƒè na z√°klade typu pr√≠kazu.`;

            console.log('\nPrompt pre ≈°peci√°lny pr√≠kaz:');
            console.log(prompt);

            const response = await this.openAIService.generateResponse(prompt, SYSTEM_PROMPTS.LEGAL, history[0]?.content || 'new_conversation');
            
            console.log('\n=== Vygenerovan√° odpoveƒè na ≈°peci√°lny pr√≠kaz ===');
            console.log(response);
            console.log('=== Koniec ≈°peci√°lneho pr√≠kazu ===\n');

            return response;
        } catch (error) {
            console.error('Chyba pri spracovan√≠ ≈°peci√°lneho pr√≠kazu:', error);
            throw error;
        }
    }

    /**
     * Detects if the question is a correction of a previous input.
     */
    private isCorrection(question: string): boolean {
        return /nie, myslel som|oprav/i.test(question);
    }

    /**
     * Extracts the corrected question from the user's input.
     */
    private extractCorrectedQuestion(question: string): string {
        const match = question.match(/myslel som (.+)$/i);
        return match ? match[1] : question;
    }

    /**
     * Checks if the question is general (non-legal).
     */
    private isGeneralQuestion(question: string): boolean {
        const isGeneral = !/z√°kon|rozhodnutie|pr√°vny|trest|s√∫d|vysvetli≈•|porovna≈•/i.test(question);
        console.log('Kontrola v≈°eobecnej ot√°zky:', isGeneral ? '√Åno' : 'Nie');
        return isGeneral;
    }

    /**
     * Determines if the question is a continuation based on context.
     */
    private isContinuation(question: string, history: ChatMessage[]): boolean {
        const isContinuation = history.length > 0 && /ƒèalej|pokraƒçova≈•|ohƒæadom/i.test(question);
        console.log('Kontrola pokraƒçovania:', isContinuation ? '√Åno' : 'Nie');
        return isContinuation;
    }

    /**
     * Decides if RAG is needed for a continuation based on history.
     */
    private needsRagForContinuation(history: ChatMessage[]): boolean {
        return history.some(msg => /z√°kon|rozhodnutie|pr√°vny/i.test(msg.content));
    }

    /**
     * Placeholder for calling the Language Model (e.g., LangChain LLM).
     */
    private async callLLM(prompt: string): Promise<string> {
        // TODO: Implement LangChain LLM call
        return 'Mock response';
    }

    /**
     * Checks if the question is a special command (e.g., summarize, export).
     */
    private isSpecialCommand(question: string): boolean {
        const isSpecial = /zhrn√∫≈•|zhrn√∫≈• to|ulo≈æi≈•|exportova≈•/i.test(question);
        console.log('Kontrola ≈°peci√°lneho pr√≠kazu:', isSpecial ? '√Åno' : 'Nie');
        return isSpecial;
    }

    /**
     * Creates a user message for the chat history.
     */
    private createUserMessage(content: string): ChatMessage {
        return {
            role: 'user',
            content: content
        };
    }

    /**
     * Creates an assistant message for the chat history.
     */
    private createAssistantMessage(content: string): ChatMessage {
        return {
            role: 'assistant',
            content: content
        };
    }
}

export const chatService = new ChatService();